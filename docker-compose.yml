version: '3.9'
services:
    redis-stack1:
        image: redis/redis-stack 
        ports:
          - "6379:6379"
          - "8001:8001"
        volumes:
          - ${PWD}/cache/:/data 
          - ${PWD}/redis-stack.conf:/redis-stack.conf

    sd:
        restart: always
        image: simple-stable-diffusion-ui:0.1  
        # build: .
        ports:
            - "8000:8000"
              # user: "1000:1000"   # replace by your uid:gid
        volumes:
            # map the output dir (of the generated images) to the host
            - ${PWD}/output:/output  
            # map the host's homedir .cache/hugging face to the container, so that 
            # we don't have to re-download the whole model every time we restart
            # the container
            - ${HOME}/.cache/huggingface/hub:/model-cache  
            - ${HOME}/.cache/huggingface/datasets:/datasets
        environment:
            - MAX_WORKERS=2
            - CUDA_VISIBLE_DEVICES=0
            - REDIS_HOST=redis-stack1
            - REDIS_PORT=6379
            - OUTPUTDIR=/output
            - HUGGINGFACE_HUB_CACHE=/model-cache
            - TRANSFORMERS_CACHE=/model-cache
            - HF_DATASETS_CACHE=/datasets
        depends_on:
            - redis-stack1
        command: /start-reload.sh
        deploy:
              # we need this to map the NVIDIA GPU
              resources:
                reservations:
                  devices:
                    - driver: nvidia
                      device_ids: ["1"]
                      capabilities: [gpu]

